{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll generate a random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of columns (features)\n",
    "K = 5\n",
    "\n",
    "#Number of records\n",
    "N = 1000\n",
    "\n",
    "#Generate an NxK matrix of uniform random variables\n",
    "X = np.random.random([N, K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peak at our data to confirm it looks as we expect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56726473,  0.88519365,  0.38457625,  0.9289916 ,  0.80676031],\n",
       "       [ 0.8374388 ,  0.06572888,  0.60501027,  0.93789147,  0.87269427],\n",
       "       [ 0.51596327,  0.57014495,  0.49929248,  0.12006497,  0.192955  ],\n",
       "       [ 0.39307975,  0.29989923,  0.13022893,  0.94546009,  0.37604155],\n",
       "       [ 0.23571947,  0.77158833,  0.95217363,  0.80786973,  0.25927613],\n",
       "       [ 0.77335227,  0.71279127,  0.8286364 ,  0.50398574,  0.38186475],\n",
       "       [ 0.79490117,  0.54187259,  0.97632271,  0.92401599,  0.80075049],\n",
       "       [ 0.57976977,  0.62170461,  0.41236319,  0.86365717,  0.58459201],\n",
       "       [ 0.81778288,  0.1194657 ,  0.57798831,  0.77566011,  0.39256776],\n",
       "       [ 0.49087861,  0.38116971,  0.80257431,  0.43860288,  0.30919184],\n",
       "       [ 0.54246161,  0.36645695,  0.2080655 ,  0.63499909,  0.77500234],\n",
       "       [ 0.33816973,  0.40838686,  0.72212608,  0.3018089 ,  0.93249856],\n",
       "       [ 0.32002848,  0.59826033,  0.3245968 ,  0.01708408,  0.83242526],\n",
       "       [ 0.27870605,  0.13622464,  0.45983858,  0.53979866,  0.72784328],\n",
       "       [ 0.36656549,  0.6741774 ,  0.51135885,  0.11953248,  0.91102448],\n",
       "       [ 0.73545237,  0.97940758,  0.77652809,  0.3597443 ,  0.07250011],\n",
       "       [ 0.10126323,  0.5300867 ,  0.56047929,  0.15793191,  0.45611761],\n",
       "       [ 0.50747887,  0.40976098,  0.28043637,  0.29946094,  0.8064903 ],\n",
       "       [ 0.69893619,  0.14357097,  0.42566789,  0.40849617,  0.32361536],\n",
       "       [ 0.58888587,  0.30434069,  0.47804832,  0.66884292,  0.22202075],\n",
       "       [ 0.35440108,  0.70932179,  0.93524608,  0.08985131,  0.7537016 ],\n",
       "       [ 0.80686155,  0.76989985,  0.18949725,  0.9885479 ,  0.46796332],\n",
       "       [ 0.34155667,  0.9778409 ,  0.15495706,  0.81567596,  0.99422143],\n",
       "       [ 0.02848531,  0.83895766,  0.96845737,  0.94201799,  0.96953297],\n",
       "       [ 0.37920745,  0.8144313 ,  0.61362221,  0.90500847,  0.14203608],\n",
       "       [ 0.95116009,  0.7950462 ,  0.31178452,  0.78255991,  0.77274691],\n",
       "       [ 0.89008563,  0.4977264 ,  0.78042143,  0.21412861,  0.58474564],\n",
       "       [ 0.05489868,  0.67033439,  0.31712238,  0.9463224 ,  0.76896218],\n",
       "       [ 0.6678361 ,  0.6976692 ,  0.68717155,  0.86074157,  0.85735165],\n",
       "       [ 0.04697121,  0.15084431,  0.78253034,  0.47838405,  0.97483836],\n",
       "       [ 0.39947715,  0.15083681,  0.4106105 ,  0.34383672,  0.87721554],\n",
       "       [ 0.01641214,  0.65373011,  0.24260726,  0.9512644 ,  0.53232489],\n",
       "       [ 0.80171161,  0.92268838,  0.41507666,  0.39455151,  0.15037355],\n",
       "       [ 0.26240065,  0.23524154,  0.62565975,  0.04452018,  0.57182216],\n",
       "       [ 0.17220446,  0.55733985,  0.49682241,  0.54611835,  0.30749788],\n",
       "       [ 0.74126628,  0.36814178,  0.0859102 ,  0.60579963,  0.36693428],\n",
       "       [ 0.10695279,  0.08286539,  0.79788255,  0.21977837,  0.83876066],\n",
       "       [ 0.81994427,  0.96975297,  0.5905776 ,  0.69958798,  0.81029233],\n",
       "       [ 0.91082962,  0.32282012,  0.04963982,  0.99001172,  0.6881969 ],\n",
       "       [ 0.0019651 ,  0.90821772,  0.99861886,  0.48120498,  0.76162516],\n",
       "       [ 0.20945193,  0.59584878,  0.82203773,  0.60920936,  0.52190042],\n",
       "       [ 0.8317118 ,  0.19771538,  0.89170463,  0.14245043,  0.31220399],\n",
       "       [ 0.60410243,  0.48223788,  0.67190076,  0.87298903,  0.71618128],\n",
       "       [ 0.30558324,  0.27879647,  0.19820234,  0.12786033,  0.26821674],\n",
       "       [ 0.02685075,  0.45636439,  0.98067055,  0.39201869,  0.49987946],\n",
       "       [ 0.87740541,  0.70160965,  0.86480351,  0.51994476,  0.83838723],\n",
       "       [ 0.64107861,  0.33764988,  0.46923204,  0.46692673,  0.75388284],\n",
       "       [ 0.59958364,  0.54533061,  0.91017482,  0.44385388,  0.90036253],\n",
       "       [ 0.4194695 ,  0.19965553,  0.8187188 ,  0.94907564,  0.83267827],\n",
       "       [ 0.33175185,  0.63426157,  0.58821991,  0.37835221,  0.06445045],\n",
       "       [ 0.57993836,  0.44666745,  0.89859752,  0.14837862,  0.73945504],\n",
       "       [ 0.20369947,  0.6738436 ,  0.31945478,  0.78395974,  0.13039157],\n",
       "       [ 0.99717181,  0.37441438,  0.04608478,  0.7524641 ,  0.1488018 ],\n",
       "       [ 0.33451778,  0.51828718,  0.62656983,  0.53409799,  0.39934404],\n",
       "       [ 0.85857388,  0.90500534,  0.9078585 ,  0.81555925,  0.92770173],\n",
       "       [ 0.57991159,  0.68149104,  0.21534942,  0.40251772,  0.10998048],\n",
       "       [ 0.77999978,  0.17224264,  0.78099993,  0.73436506,  0.76367401],\n",
       "       [ 0.87413223,  0.76188908,  0.87692062,  0.14864862,  0.89034525],\n",
       "       [ 0.03833406,  0.44300709,  0.9429029 ,  0.8313747 ,  0.23296226],\n",
       "       [ 0.73377542,  0.1517143 ,  0.89500559,  0.39825168,  0.74437585],\n",
       "       [ 0.55824941,  0.71890299,  0.85113216,  0.86203772,  0.57542134],\n",
       "       [ 0.29263532,  0.86934227,  0.77496971,  0.60723255,  0.85331039],\n",
       "       [ 0.48242717,  0.40553313,  0.03815815,  0.44939128,  0.69797913],\n",
       "       [ 0.30439056,  0.91322867,  0.1433853 ,  0.59381671,  0.10046408],\n",
       "       [ 0.21379296,  0.45927319,  0.58006773,  0.61826923,  0.42893699],\n",
       "       [ 0.98926617,  0.37712274,  0.6360081 ,  0.89879486,  0.75096324],\n",
       "       [ 0.27562908,  0.11222963,  0.18852962,  0.30104364,  0.04867248],\n",
       "       [ 0.85217001,  0.20778352,  0.61683955,  0.03842825,  0.43063046],\n",
       "       [ 0.31977615,  0.67135766,  0.00754901,  0.35561295,  0.83480543],\n",
       "       [ 0.92483876,  0.38324584,  0.26170507,  0.08595   ,  0.85841969],\n",
       "       [ 0.11600583,  0.5763355 ,  0.53441943,  0.44372216,  0.11062101],\n",
       "       [ 0.07120997,  0.08525657,  0.00944025,  0.93666958,  0.96368868],\n",
       "       [ 0.92005971,  0.54027651,  0.98713728,  0.86581849,  0.67369713],\n",
       "       [ 0.2030213 ,  0.44605744,  0.41027392,  0.57970669,  0.26684584],\n",
       "       [ 0.5597934 ,  0.84191161,  0.52452144,  0.66862324,  0.67395438],\n",
       "       [ 0.7111105 ,  0.69054647,  0.18720167,  0.55361384,  0.46948294],\n",
       "       [ 0.20001103,  0.48428051,  0.86644517,  0.35914009,  0.97182437],\n",
       "       [ 0.20611743,  0.04009286,  0.48941733,  0.11009053,  0.29939969],\n",
       "       [ 0.53831409,  0.78223072,  0.38749426,  0.86108788,  0.41050433],\n",
       "       [ 0.26549744,  0.06346452,  0.71430836,  0.61175277,  0.44944494],\n",
       "       [ 0.55978417,  0.43850445,  0.89389893,  0.76542368,  0.50217765],\n",
       "       [ 0.9676015 ,  0.58509969,  0.27844792,  0.73169424,  0.63960194],\n",
       "       [ 0.65030892,  0.20660637,  0.35180648,  0.38624272,  0.81585076],\n",
       "       [ 0.17946191,  0.45030699,  0.51780232,  0.27060706,  0.68871124],\n",
       "       [ 0.65851837,  0.3017823 ,  0.11505632,  0.35793913,  0.70479191],\n",
       "       [ 0.89456521,  0.68837528,  0.50928776,  0.51264852,  0.9868656 ],\n",
       "       [ 0.29664178,  0.91231152,  0.25510293,  0.43704879,  0.50490406],\n",
       "       [ 0.36535158,  0.47304373,  0.72647876,  0.34136084,  0.66441709],\n",
       "       [ 0.00985248,  0.96747988,  0.02577832,  0.4691919 ,  0.09051292],\n",
       "       [ 0.62629941,  0.52569498,  0.84001144,  0.28603408,  0.43327683],\n",
       "       [ 0.08515738,  0.87888046,  0.87529099,  0.05879546,  0.89457316],\n",
       "       [ 0.27715777,  0.02917656,  0.36828211,  0.71556113,  0.0112903 ],\n",
       "       [ 0.67979936,  0.09062055,  0.60057913,  0.00913609,  0.19988208],\n",
       "       [ 0.46152289,  0.90160455,  0.43017683,  0.59773215,  0.19085342],\n",
       "       [ 0.89075473,  0.85215885,  0.1192885 ,  0.92119846,  0.77469958],\n",
       "       [ 0.10888103,  0.20509855,  0.80721823,  0.85410043,  0.7664439 ],\n",
       "       [ 0.45236562,  0.70240164,  0.39346369,  0.99096732,  0.9097725 ],\n",
       "       [ 0.20799161,  0.23284876,  0.64422235,  0.71636092,  0.1461139 ],\n",
       "       [ 0.94922366,  0.69065932,  0.38860711,  0.25258281,  0.85444715],\n",
       "       [ 0.71068535,  0.1859562 ,  0.48411783,  0.43418464,  0.02463864]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the first 100 rows\n",
    "X[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the dimensions of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about designing a scoring function for a logistic regression. As we are not concerned with fitting a model to data, we can just make up a logistic regression. <br> <br>\n",
    "\n",
    "For quick intro, the Logistic Regression takes the form of $\\hat{Y} = f(x * \\beta^T)$, where $x$ is the $1xK$ vector of features and $\\beta$ is the $1xK$ vector of weights. The function $f$, called a 'link' function, is the inverse logit: <br><br>\n",
    "\n",
    "<center>$f(a)=\\frac{1}{1+e^{-a}}$</center> <br><br>\n",
    "\n",
    "In this notebook we'll write a function that, given inputs of $X$ and $\\beta$, returns a value for $\\hat{Y}$.\n",
    "<br><br>\n",
    "First let's generate a random set of weights to represent $\\beta$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.72543572, -0.53606537, -0.05166586, -0.09036846,  0.05471693])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate a K dimensional vector of uniform random variables in the interval [-1, 1]\n",
    "beta = 2*(np.random.random(K) - 0.5)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we applied a neat NumPy trick here. The numpy.random.random() function returns an array, yet we applied what appears to be a scalar operation on the vector. This is an example of what NumPy calls vectorization (a major point of this tutorial), which offers us both a very fast way to do run vector computations as well as a clean and concise method of coding. \n",
    "\n",
    "<br><br>\n",
    "\n",
    "<b>Question: we designed the above $beta$ vector such that $E[\\beta_i]=0$. How can we confirm that we did this correctly?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2674231384214707"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start by taking the mean of the beta we already calculated\n",
    "beta.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is likely the above is not equal to zero. Let's simulate this 100k times and see what the distribution of means is\n",
    "means = []\n",
    "\n",
    "for i in range(100000): \n",
    "    beta = 2*(np.random.random(K) - 0.5)\n",
    "    means.append(beta.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use matplotlibs hist function to plot the histogram of means here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEpxJREFUeJzt3XusXeV55/Hvb3CKmCQwXFzXY0xNFWskg6YkWB4rjWao\nGBWHqGMiJZHRKHhUC7eCRonUVjKNNI0UWYKREiSkAYkUhEGZEJRLsQrMiECkqFMBPSCCsSnBKUZw\nZLALCKd/hNb0mT/2ezrbh2O/57LP2cfJ9yMt7bWftd69nn2B31mXvZ2qQpKkU/lX425AkrT8GRaS\npC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkda0YdwPzdcEFF9S6devG3YYknVaefvrp\nv6+qlXMdd9qGxbp165iYmBh3G5J0WknyynzGeRhKktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuw\nkCR1GRaSpC7DQpLUddp+g1vqWbfrobFs99DNnxrLdqXF5J6FJKnLsJAkdRkWkqQuw0KS1NUNiyRr\nk/wwyYEk+5N8sdW/kmQyybNtunpozE1JDiZ5MclVQ/XLk+xry25LklY/M8m3W/3JJOtG/1QlSfM1\nmz2L48AfVdUGYDNwY5INbdmtVXVZmx4GaMu2AZcAW4Dbk5zR1r8DuB5Y36Ytrb4DeLuqPgLcCtyy\n8KcmSRqVblhU1eGqeqbN/wx4AVhziiFbgfur6t2qehk4CGxKsho4u6qeqKoC7gWuGRqzp81/B7hy\naq9DkjR+czpn0Q4PfRR4spW+kOS5JHcnObfV1gCvDg17rdXWtPnp9RPGVNVx4B3g/Ln0JklaPLMO\niyQfAr4LfKmqjjE4pPQbwGXAYeBri9LhiT3sTDKRZOLo0aOLvTlJUjOrsEjyAQZB8c2q+h5AVb1R\nVe9V1T8D3wA2tdUngbVDwy9stck2P71+wpgkK4BzgDen91FVd1bVxqrauHLlnP+9cUnSPM3maqgA\ndwEvVNXXh+qrh1b7NPB8m98LbGtXOF3M4ET2U1V1GDiWZHN7zOuAB4fGbG/znwEeb+c1JEnLwGx+\nG+q3gM8D+5I822p/Clyb5DKggEPA7wNU1f4kDwAHGFxJdWNVvdfG3QDcA5wFPNImGITRfUkOAm8x\nuJpKOi2N6zepwN+l0uLphkVV/RUw05VJD59izG5g9wz1CeDSGeo/Bz7b60WSNB5+g1uS1GVYSJK6\nDAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuw\nkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJ\nUpdhIUnqMiwkSV2GhSSpy7CQJHV1wyLJ2iQ/THIgyf4kX2z185I8muSldnvu0JibkhxM8mKSq4bq\nlyfZ15bdliStfmaSb7f6k0nWjf6pSpLmazZ7FseBP6qqDcBm4MYkG4BdwGNVtR54rN2nLdsGXAJs\nAW5PckZ7rDuA64H1bdrS6juAt6vqI8CtwC0jeG6SpBHphkVVHa6qZ9r8z4AXgDXAVmBPW20PcE2b\n3wrcX1XvVtXLwEFgU5LVwNlV9URVFXDvtDFTj/Ud4MqpvQ5J0vjN6ZxFOzz0UeBJYFVVHW6LXgdW\ntfk1wKtDw15rtTVtfnr9hDFVdRx4Bzh/hu3vTDKRZOLo0aNzaV2StACzDoskHwK+C3ypqo4NL2t7\nCjXi3t6nqu6sqo1VtXHlypWLvTlJUjOrsEjyAQZB8c2q+l4rv9EOLdFuj7T6JLB2aPiFrTbZ5qfX\nTxiTZAVwDvDmXJ+MJGlxzOZqqAB3AS9U1deHFu0Ftrf57cCDQ/Vt7QqnixmcyH6qHbI6lmRze8zr\npo2ZeqzPAI+3vRVJ0jKwYhbr/BbweWBfkmdb7U+Bm4EHkuwAXgE+B1BV+5M8ABxgcCXVjVX1Xht3\nA3APcBbwSJtgEEb3JTkIvMXgaipJ0jLRDYuq+ivgZFcmXXmSMbuB3TPUJ4BLZ6j/HPhsrxdJ0nj4\nDW5JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJElds/khQWlB\n1u16aNwtSFog9ywkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuw\nkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKmrGxZJ7k5yJMnzQ7WvJJlM8mybrh5a\ndlOSg0leTHLVUP3yJPvastuSpNXPTPLtVn8yybrRPkVJ0kLNZs/iHmDLDPVbq+qyNj0MkGQDsA24\npI25PckZbf07gOuB9W2aeswdwNtV9RHgVuCWeT4XSdIi6YZFVf0IeGuWj7cVuL+q3q2ql4GDwKYk\nq4Gzq+qJqirgXuCaoTF72vx3gCun9jokScvDQs5ZfCHJc+0w1bmttgZ4dWid11ptTZufXj9hTFUd\nB94Bzl9AX5KkEVsxz3F3AF8Fqt1+Dfi9UTV1Mkl2AjsBLrroosXenHTaWbfrobFs99DNnxrLdrV0\n5rVnUVVvVNV7VfXPwDeATW3RJLB2aNULW22yzU+vnzAmyQrgHODNk2z3zqraWFUbV65cOZ/WJUnz\nMK+waOcgpnwamLpSai+wrV3hdDGDE9lPVdVh4FiSze18xHXAg0Njtrf5zwCPt/MakqRlonsYKsm3\ngCuAC5K8BvwZcEWSyxgchjoE/D5AVe1P8gBwADgO3FhV77WHuoHBlVVnAY+0CeAu4L4kBxmcSN82\niicmSRqdblhU1bUzlO86xfq7gd0z1CeAS2eo/xz4bK8PSdL4+A1uSVKXYSFJ6jIsJEldhoUkqcuw\nkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJ\nUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1\nGRaSpC7DQpLU1Q2LJHcnOZLk+aHaeUkeTfJSuz13aNlNSQ4meTHJVUP1y5Psa8tuS5JWPzPJt1v9\nySTrRvsUJUkLNZs9i3uALdNqu4DHqmo98Fi7T5INwDbgkjbm9iRntDF3ANcD69s09Zg7gLer6iPA\nrcAt830ykqTF0Q2LqvoR8Na08lZgT5vfA1wzVL+/qt6tqpeBg8CmJKuBs6vqiaoq4N5pY6Ye6zvA\nlVN7HZKk5WG+5yxWVdXhNv86sKrNrwFeHVrvtVZb0+an108YU1XHgXeA8+fZlyRpESz4BHfbU6gR\n9NKVZGeSiSQTR48eXYpNSpKYf1i80Q4t0W6PtPoksHZovQtbbbLNT6+fMCbJCuAc4M2ZNlpVd1bV\nxqrauHLlynm2Lkmaq/mGxV5ge5vfDjw4VN/WrnC6mMGJ7KfaIatjSTa38xHXTRsz9VifAR5veyuS\npGViRW+FJN8CrgAuSPIa8GfAzcADSXYArwCfA6iq/UkeAA4Ax4Ebq+q99lA3MLiy6izgkTYB3AXc\nl+QggxPp20byzCRJI9MNi6q69iSLrjzJ+ruB3TPUJ4BLZ6j/HPhsrw9J0vj4DW5JUpdhIUnqMiwk\nSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK7uT5Tr\nF8O6XQ+NuwVJpzH3LCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSp\ny7CQJHUZFpKkLsNCktRlWEiSuvyJckkLNs6fwD9086fGtu1fJu5ZSJK6FhQWSQ4l2Zfk2SQTrXZe\nkkeTvNRuzx1a/6YkB5O8mOSqofrl7XEOJrktSRbSlyRptEaxZ/HbVXVZVW1s93cBj1XVeuCxdp8k\nG4BtwCXAFuD2JGe0MXcA1wPr27RlBH1JkkZkMQ5DbQX2tPk9wDVD9fur6t2qehk4CGxKsho4u6qe\nqKoC7h0aI0laBhYaFgX8IMnTSXa22qqqOtzmXwdWtfk1wKtDY19rtTVtfnr9fZLsTDKRZOLo0aML\nbF2SNFsLvRrqE1U1meRXgUeT/O3wwqqqJLXAbQw/3p3AnQAbN24c2eNKkk5tQXsWVTXZbo8A3wc2\nAW+0Q0u02yNt9Ulg7dDwC1ttss1Pr0uSlol5h0WSDyb58NQ88DvA88BeYHtbbTvwYJvfC2xLcmaS\nixmcyH6qHbI6lmRzuwrquqExkqRlYCGHoVYB329Xua4A/ldV/e8kfwM8kGQH8ArwOYCq2p/kAeAA\ncBy4sarea491A3APcBbwSJskScvEvMOiqv4O+M0Z6m8CV55kzG5g9wz1CeDS+fYiSVpcfoNbktRl\nWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaF\nJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUte8/w1uzc+6XQ+NuwVJmjP3LCRJXYaFJKnLsJAkdRkW\nkqQuw0KS1OXVUJJOa+O6wvDQzZ8ay3bHxT0LSVKXYSFJ6jIsJEldhoUkqWvZhEWSLUleTHIwya5x\n9yNJ+v+WRVgkOQP4n8AngQ3AtUk2jLcrSdKU5XLp7CbgYFX9HUCS+4GtwIHF2Jg/5idJc7NcwmIN\n8OrQ/deA/zCmXiSpa5x/dI7jOx7LJSxmJclOYGe7+w9JXhxnPydxAfD3425iFuxzdE6HHsE+R21s\nfeaWOa0+vc9fn882l0tYTAJrh+5f2GonqKo7gTuXqqn5SDJRVRvH3UePfY7O6dAj2Oeo/bL1uSxO\ncAN/A6xPcnGSXwG2AXvH3JMkqVkWexZVdTzJHwL/BzgDuLuq9o+5LUlSsyzCAqCqHgYeHncfI7Cs\nD5MNsc/ROR16BPsctV+qPlNVo3gcSdIvsOVyzkKStIwZFvOQ5LwkjyZ5qd2eO8M6/y7Js0PTsSRf\nasu+kmRyaNnV4+qzrXcoyb7Wy8Rcxy92j0nWJvlhkgNJ9if54tCyRX0tez9Dk4Hb2vLnknxstmOX\nuM//2vrbl+Svk/zm0LIZ3/8x9HhFkneG3sv/PtuxS9znnwz1+HyS95Kc15YtyWvZtnV3kiNJnj/J\n8tF+NqvKaY4T8D+AXW1+F3BLZ/0zgNeBX2/3vwL88XLpEzgEXLDQ57lYPQKrgY+1+Q8DPwE2LPZr\n2d63nwK/AfwK8OOp7Q6tczXwCBBgM/DkbMcucZ8fB85t85+c6vNU7/8YerwC+Mv5jF3KPqet/7vA\n40v5Wg5t6z8CHwOeP8nykX423bOYn63Anja/B7ims/6VwE+r6pVF7er95trnqMePZBtVdbiqnmnz\nPwNeYPCt/8X2Lz9DU1X/CEz9DM2wrcC9NfAE8G+SrJ7l2CXrs6r+uqrebnefYPBdpqW0kNdjWb2W\n01wLfGuRejmlqvoR8NYpVhnpZ9OwmJ9VVXW4zb8OrOqsv433f6C+0HYN716MwzvNbPss4AdJns7g\nW/JzHb8UPQKQZB3wUeDJofJivZYz/QzN9JA62TqzGTsqc93WDgZ/cU452fs/SrPt8ePtvXwkySVz\nHDsKs95Wkn8NbAG+O1Reitdytkb62Vw2l84uN0l+APzaDIu+PHynqirJSS8py+BLhv8FuGmofAfw\nVQYfrK8CXwN+b4x9fqKqJpP8KvBokr9tf7XMdvxS9EiSDzH4D/NLVXWslUf2Wv4ySPLbDMLiE0Pl\n7vu/RJ4BLqqqf2jnnv4CWD+GPmbrd4H/W1XDf90vl9dy5AyLk6iq/3yyZUneSLK6qg633bojp3io\nTwLPVNUbQ4/9L/NJvgH85Tj7rKrJdnskyfcZ7Kb+CJjL81zUHpN8gEFQfLOqvjf02CN7LWcwm5+h\nOdk6H5jF2FGZ1c/lJPn3wJ8Dn6yqN6fqp3j/l7THoT8AqKqHk9ye5ILZjF3KPoe874jBEr2WszXS\nz6aHoeZnL7C9zW8HHjzFuu87ptn+pzjl08CMVzOMQLfPJB9M8uGpeeB3hvqZy/NczB4D3AW8UFVf\nn7ZsMV/L2fwMzV7gunblyWbgnXZYbSl/wqa7rSQXAd8DPl9VPxmqn+r9X+oef6291yTZxOD/T2/O\nZuxS9tn6Owf4Twx9XpfwtZyt0X42l+Ks/S/aBJwPPAa8BPwAOK/V/y3w8NB6H2TwYT9n2vj7gH3A\nc+1NWj2uPhlcEfHjNu0HvtwbP4YeP8HgMNNzwLNtunopXksGV5T8hMHVI19utT8A/qDNh8E/3PXT\n1sfGU41dxM9kr88/B94eev0meu//GHr8w9bDjxmchP/4cnwt2/3/Btw/bdySvZZte98CDgP/xOC8\nw47F/Gz6DW5JUpeHoSRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnq+n8udrz1/jNi\nHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108988d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect the distribution to be centered around zero. Is it? As fun technical side, let's dive a little deeper into what this distribution should look like. The histogram shows a distribution of the average of a sample of 5 uniformly distributed random variables taken over N different samples. Can we compare this to a theoretical distribution?<br>\n",
    "\n",
    "Yes we can! We sampled each $\\beta_i$ from a uniform distribution over the interval $[-1, 1]$. The variance of a sample of uniformly distributed variables is given by $(1/12) * (b - a)^2$, where $b$ and $a$ are the min/max of the support interval. The standard error (or the standard deviation of the mean) of a sample of size K with with $Var(X) = \\sigma^2$ is $\\sigma / \\sqrt(K)$. <br>\n",
    "\n",
    "Given the above knowledge, we should expect our distribution of averages to be normally distributed with mean = 0 and var = $(12 * 5)^{-1} * (1 - (-1))^2 = 0.66667$. Let's compare this normal distribution to our sample above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZKH/BUATHoKkowxpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c0280d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compute a vector from the normal distribution specified above\n",
    "from scipy.stats import norm\n",
    "mu = 0\n",
    "sig = np.sqrt(4 / 60.0) \n",
    "xs = np.linspace(-1, 1, 1000)\n",
    "ys = norm.pdf(xs, mu, sig) \n",
    "\n",
    "plt.hist(means, normed = True)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write our scoring function. Let's try to use as much of Numpy's inner optimization as possible (hint, this can be done in two lines and without writing any loops). The key is that numpy functions that would normally take in a scalar can also take in an array, and the function applies the operations element wise to the array and returns an array. i.e.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_array = np.array([-1, 1])\n",
    "np.abs(ex_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this feature to write a fast and clean scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_logistic_regression(X, beta):\n",
    "    '''\n",
    "    This function takes in an NxK matrix X and 1xK vector beta.\n",
    "    The function should apply the logistic scoring function to each record of X.\n",
    "    The output should be an Nx1 vector of scores\n",
    "    '''\n",
    "    \n",
    "    #First let's calculate X*beta - make sure to use numpy's 'dot' method\n",
    "    xbeta = X.dot(beta)\n",
    "    \n",
    "    #Now let's input this into the link function\n",
    "    \n",
    "    prob_score = 1/(1 + np.exp(-1 * xbeta))\n",
    "    \n",
    "    return prob_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how much faster is it by using Numpy? We can test this be writing the same function that uses no Numpy and executes via loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_logistic_regression_NoNumpy(X, beta):\n",
    "    '''\n",
    "    This function takes in an NxK matrix X and 1xK vector beta.\n",
    "    The function should apply the logistic scoring function to each record of X.\n",
    "    The output should be an Nx1 vector of scores\n",
    "    '''\n",
    "    #Let's calculate xbeta using loops\n",
    "    xbeta = []\n",
    "    for row in X:\n",
    "        \n",
    "        xb = 0\n",
    "        for i, el in enumerate(row):\n",
    "            xb += el * beta[i]\n",
    "        \n",
    "        xbeta.append(xb)\n",
    "        \n",
    "    #Now let's apply the link function to each xbeta\n",
    "    prob_score = []\n",
    "    for xb in xbeta:\n",
    "        p = (1 / (1 + np.exp(-1 * xb)))  \n",
    "        prob_score.append(p)\n",
    "        \n",
    "    return prob_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any analysis, let's test the output of each to make sure they equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Deviation = 0.0\n"
     ]
    }
   ],
   "source": [
    "#Student - write a unit test that calls each function with the same inputs and checks to see they return \n",
    "#the same values. \n",
    "diff = np.abs(score_logistic_regression_NoNumpy(X, beta) - score_logistic_regression(X, beta))\n",
    "\n",
    "print(\"Mean Absolute Deviation = {}\".format(np.round(diff.sum(), 8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If they equal then we can proceed with timing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.78 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit score_logistic_regression_NoNumpy(X, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 15.10 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 21.3 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit score_logistic_regression(X, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
